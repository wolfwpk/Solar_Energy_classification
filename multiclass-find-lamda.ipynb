{
 "cells": [],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     "\n",
     "#!/usr/bin/env python3\n",
     "# -*- coding: utf-8 -*-\n",
     "\"\"\"\n",
     "Created on Wed Nov 17 20:12:15 2021\n",
     "\n",
     "@author: aprilz\n",
     "\"\"\"\n",
     "\n",
     "# import auto diff\n",
     "\n",
     "import torch\n",
     "from autograd import grad\n",
     "from autograd import numpy as np\n",
     "import matplotlib.pyplot as plt\n",
     "from autograd.misc.flatten import flatten_func\n",
     "from autograd import value_and_grad\n",
     "import pandas as pd\n",
     "import time\n",
     "\n",
     "\n",
     "#!/usr/bin/env python3\n",
     "# -*- coding: utf-8 -*-\n",
     "\"\"\"\n",
     "Created on Wed Nov 17 20:12:15 2021\n",
     "\n",
     "@author: aprilz\n",
     "\"\"\"\n",
     "\n",
     "# import auto diff\n",
     "\n",
     "import torch\n",
     "from autograd import grad\n",
     "from autograd import numpy as np\n",
     "import matplotlib.pyplot as plt\n",
     "from autograd.misc.flatten import flatten_func\n",
     "from autograd import value_and_grad\n",
     "import pandas as pd\n",
     "import time\n",
     "\n",
     "data = pd.read_csv(\"dataCollection.csv\")\n",
     "\n",
     "number = data['USAF'].values\n",
     "latitude = data['Latitude'].values\n",
     "longitude = data['Longitude'].values\n",
     "etr = data['Avg hourly ETR in 2005 (Wh/m^2)'].values\n",
     "length = number.size\n",
     "train_length = 600\n",
     "test_length = length - train_length\n",
     "classes = np.empty(length,dtype=int)\n",
     "\n",
     "#standard normalization\n",
     "var_x = np.var(longitude)\n",
     "var_y = np.var(latitude)\n",
     "mean_x = np.mean(longitude)\n",
     "mean_y = np.mean(latitude)\n",
     "x_norm = (longitude - mean_x)/np.sqrt(var_x)\n",
     "y_norm = (latitude - mean_y)/np.sqrt(var_y)\n",
     "\n",
     "\n",
     "#define classes labels\n",
     "for i in range(length):\n",
     "    if etr[i] < 320:\n",
     "        classes[i]=0\n",
     "        # latitude[i]= latitude[i]+10\n",
     "        # longitude[i]= longitude[i]+10\n",
     "    elif 320 < etr[i] < 340:\n",
     "        classes[i]=1\n",
     "    else:\n",
     "        classes[i]=2\n",
     "        # latitude[i]= latitude[i]-10\n",
     "        # longitude[i]= longitude[i]-10\n",
     "\n",
     "#shuffle and pick train set and test set\n",
     "shuffle_index = np.arange(length)\n",
     "np.random.shuffle(shuffle_index)\n",
     "x_norm = x_norm[shuffle_index]\n",
     "y_norm = y_norm[shuffle_index]\n",
     "classes = classes[shuffle_index]\n",
     "x_train = x_norm[:train_length]\n",
     "y_train = y_norm[:train_length]\n",
     "classes_train = classes[:train_length]\n",
     "x_test = x_norm[train_length:]\n",
     "y_test = y_norm[train_length:]\n",
     "classes_test = classes[train_length:]\n",
     "\n",
     "\n",
     "# compute C linear combinations, one per classifier\n",
     "def model(x,w):\n",
     "    a = w[0] + np.dot(x.T,w[1:])\n",
     "    return a.T\n",
     "\n",
     "# multiclass perceptron\n",
     "lam = 1 # reg param\n",
     "def multiclass_perceptron(w):\n",
     "    # pre-compute predictions on all points\n",
     "    all_evals = model(x,w)\n",
     "    # compute max across data points\n",
     "    a = np.max(all_evals,axis = 0)\n",
     "    # compute cost in compact form using numpy broadcasting\n",
     "    b = all_evals[y.astype(int),np.arange(np.size(y))]\n",
     "    cost = np.sum(a-b)\n",
     "    # add reg\n",
     "    cost = cost + lam*np.linalg.norm(w[1:,:],'fro')**2\n",
     "    # return average\n",
     "    return cost/float(np.size(y))\n",
     "\n",
     "# gradient descent function\n",
     "def gradient_descent(g, step, max_its, w):\n",
     "    # flatten g\n",
     "    g_flat, unflatten_func, w_flat = flatten_func(g,w)\n",
     "    # compute gradient\n",
     "    gradient = grad(g_flat)\n",
     "    # gradient descent loop\n",
     "    weight_history = [w_flat] # weight history container\n",
     "    cost_history = [g_flat(w_flat)] # cost history container\n",
     "    for k in range(max_its):\n",
     "        # eval gradient\n",
     "        grad_eval = gradient(w_flat)\n",
     "        grad_eval_norm = grad_eval / np.linalg.norm(grad_eval)\n",
     "        # take grad descent step\n",
     "        alpha = 1/(k+1)\n",
     "        w_flat = w_flat - alpha*grad_eval_norm\n",
     "        # record weight and cost\n",
     "        weight_history.append(w_flat)\n",
     "        cost_history.append(g_flat(w_flat))\n",
     "    return weight_history, cost_history, unflatten_func\n",
     "\n",
     "\n",
     "C = 3 # No. of classes\n",
     "iter = 1000\n",
     "N = 2 #No. of features\n",
     "x = np.c_[x_train,y_train].T\n",
     "y = classes_train.T.reshape(1,-1)\n",
     "w = np.random.random((N+1,C)) #w0, w1, w2\n",
     "\n",
     "#train models\n",
     "train_start = time.time()\n",
     "a, b, unflatten = gradient_descent(multiclass_perceptron,'d',iter,w)\n",
     "wp = unflatten(a[iter])\n",
     "train_end = time.time()\n",
     "print(\"train time:%fs\"%(train_end-train_start))\n",
     "\n",
     "#plot loss\n",
     "plt.figure(1)\n",
     "plt.plot(b)\n",
     "print(b[-1])\n",
     "\n",
     "#plot test point\n",
     "colors = ['g','b','r']\n",
     "plt.figure(figsize=(10,6),dpi=200)\n",
     "plt.xlim(-3, 3)\n",
     "plt.ylim(-3, 3)\n",
     "plt.grid(1)\n",
     "plt.xlabel('longitude')\n",
     "plt.ylabel('latitude')\n",
     "for target in range(test_length):\n",
     "    plt.scatter(x_norm[target], y_norm[target], c=colors[classes[target]],s=8)\n",
     "\n",
     "#verify test dataset\n",
     "data_verify = np.c_[x_test,y_test].T\n",
     "test_start = time.time()\n",
     "verify_result = z=np.argmax(model(data_verify, wp),axis=0)\n",
     "test_end = time.time()\n",
     "print(\"test time:%fs\"%(test_end-test_start))\n",
     "true_number = 0\n",
     "for i in range(test_length):\n",
     "    if verify_result[i] == classes_test[i]:\n",
     "        true_number = true_number +1\n",
     "print(true_number, true_number/test_length)\n",
     "\n",
     "# xp1, xp2 = np.meshgrid(np.linspace(-140,-60,100),np.linspace(20, 80, 100))\n",
     "xp1, xp2 = np.meshgrid(np.linspace(-3, 3,100),np.linspace(-3, 3, 100))\n",
     "# vectorize mesh grid\n",
     "xp1_v = xp1.reshape(-1,1)\n",
     "xp2_v = xp2.reshape(-1,1)\n",
     "Xp_data = np.append(xp1_v,xp2_v,axis=1)\n",
     "\n",
     "classes_area=np.argmax(model(Xp_data.T,wp),axis=0)\n",
     "classes_area=classes_area.reshape(xp1.shape)\n",
     "plt.contourf(xp1,xp2,classes_area,cmap=plt.cm.hot, alpha=.3)\n",
     "plt.xlabel('x1')\n",
     "plt.ylabel('x2');\n",
     "\n",
     "\n",
     "\n",
     "lam = 10**5 # reg param\n",
     "w_norm = []\n",
     "for n in range(10):\n",
     "    lam = lam/10\n",
     "    a, b, unflatten = gradient_descent(multiclass_perceptron,'d',iter,w)\n",
     "    wp = unflatten(a[iter])\n",
     "    \n",
     "    #verify test dataset\n",
     "    data_verify = np.c_[x_test,y_test].T\n",
     "    test_start = time.time()\n",
     "    verify_result = z=np.argmax(model(data_verify, wp),axis=0)\n",
     "test_end = time.time()\n",
     "print(\"test time:%fs\"%(test_end-test_start))\n",
     "true_number = 0\n",
     "for i in range(test_length):\n",
     "    if verify_result[i] == classes_test[i]:\n",
     "        true_number = true_number +1\n",
     "print(true_number, true_number/test_length)\n",
     "    print(lam, true_number, true_number/length)\n",
     "    loss.append(b[-1])\n",
     "    w_norm.append(np.linalg.norm(wp[1:,:],'fro')**2)\n",
     "plt.plot(loss)\n",
     "plt.plot(w_norm)\n",
     "\n",
     "\n",
     "\n",
     "\n"
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}